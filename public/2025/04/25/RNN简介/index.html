<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>RNN简介 | Loire's Blog</title><meta name="author" content="Loire"><meta name="copyright" content="Loire"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="RNN(循环神经网络)简要介绍 简介 循环神经网络模型以序列数据为输入（数据内部的元素是有顺序关系的），如文章、语句、一周的天气信息、三个月的股市指数等。与传统的前馈网络不同的是，RNN模型处理序列数据能够获取更多的语义信息，时序信息等。 处理任务示例： 以NER（命名实体识别）为例，从自然语言文本中识别真实世界中的实体名及其类别。如： 句子1：I like eating apple!—"><meta property="og:type" content="website"><meta property="og:title" content="RNN简介"><meta property="og:url" content="https://ccloire.com/2025/04/25/RNN%E7%AE%80%E4%BB%8B/index.html"><meta property="og:site_name" content="Loire&#39;s Blog"><meta property="og:description" content="RNN(循环神经网络)简要介绍 简介 循环神经网络模型以序列数据为输入（数据内部的元素是有顺序关系的），如文章、语句、一周的天气信息、三个月的股市指数等。与传统的前馈网络不同的是，RNN模型处理序列数据能够获取更多的语义信息，时序信息等。 处理任务示例： 以NER（命名实体识别）为例，从自然语言文本中识别真实世界中的实体名及其类别。如： 句子1：I like eating apple!—"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://ccloire.com/img/butterfly-icon.png"><meta property="article:published_time" content="2025-04-25T05:05:09.000Z"><meta property="article:modified_time" content="2025-04-25T05:08:23.722Z"><meta property="article:author" content="Loire"><meta property="article:tag" content="深度学习"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://ccloire.com/img/butterfly-icon.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://ccloire.com/2025/04/25/RNN%E7%AE%80%E4%BB%8B/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>(()=>{const e={set:(e,t,o)=>{if(!o)return;const a=Date.now()+864e5*o;localStorage.setItem(e,JSON.stringify({value:t,expiry:a}))},get:e=>{const t=localStorage.getItem(e);if(!t)return;const{value:o,expiry:a}=JSON.parse(t);if(!(Date.now()>a))return o;localStorage.removeItem(e)}};window.btf={saveToLocal:e,getScript:(e,t={})=>new Promise((o,a)=>{const n=document.createElement("script");n.src=e,n.async=!0,Object.entries(t).forEach(([e,t])=>n.setAttribute(e,t)),n.onload=n.onreadystatechange=()=>{n.readyState&&!/loaded|complete/.test(n.readyState)||o()},n.onerror=a,document.head.appendChild(n)}),getCSS:(e,t)=>new Promise((o,a)=>{const n=document.createElement("link");n.rel="stylesheet",n.href=e,t&&(n.id=t),n.onload=n.onreadystatechange=()=>{n.readyState&&!/loaded|complete/.test(n.readyState)||o()},n.onerror=a,document.head.appendChild(n)}),addGlobalFn:(e,t,o=!1,a=window)=>{if(e.startsWith("pjax"))return;const n=a.globalFn||{};n[e]=n[e]||{},n[e][o||Object.keys(n[e]).length]=t,a.globalFn=n}};const t=()=>{document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},o=()=>{document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#ffffff")};btf.activateDarkMode=t,btf.activateLightMode=o;const a=e.get("theme");"dark"===a?t():"light"===a&&o();const n=e.get("aside-status");void 0!==n&&document.documentElement.classList.toggle("hide-aside","hide"===n);/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple")})()</script><script>const GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:void 0,translate:void 0,highlight:{plugin:"highlight.js",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:!1,highlightFullpage:!1,highlightMacStyle:!1},copy:{success:"复制成功",error:"复制失败",noSupport:"浏览器不支持"},relativeDate:{homepage:!1,post:!1},runtime:"",dateSuffix:{just:"刚刚",min:"分钟前",hour:"小时前",day:"天前",month:"个月前"},copyright:void 0,lightbox:"null",Snackbar:void 0,infinitegrid:{js:"https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js",buttonText:"加载更多"},isPhotoFigcaption:!1,islazyloadPlugin:!1,isAnchor:!1,percent:{toc:!0,rightside:!1},autoDarkmode:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"RNN简介",isHighlightShrink:!1,isToc:!1,pageType:"posts"}</script><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="Loire's Blog" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/butterfly-icon.png" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">9</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">6</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 文章发布时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-heartbeat"></i><span> 清单</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/shuoshuo/"><i class="fa-fw fas fa-comment"></i><span> 说说</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="not-home-page" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><img class="site-icon" src="https://caimotu.top/Picgo/微信图片_20250226100519.jpg" alt="Logo"><span class="site-name">Loire's Blog</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 文章发布时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-heartbeat"></i><span> 清单</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/shuoshuo/"><i class="fa-fw fas fa-comment"></i><span> 说说</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="page-site-info"><h1 id="site-title">RNN简介</h1></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1 id="rnn循环神经网络简要介绍">RNN(循环神经网络)简要介绍</h1><h2 id="简介">简介</h2><p>循环神经网络模型以序列数据为输入（数据内部的元素是有顺序关系的），如文章、语句、一周的天气信息、三个月的股市指数等。与传统的前馈网络不同的是，RNN模型处理序列数据能够获取更多的语义信息，时序信息等。</p><p>处理任务示例：</p><p>以NER（命名实体识别）为例，从自然语言文本中识别真实世界中的实体名及其类别。如：</p><p>句子1：I like eating apple!——其中的apple指的是苹果食物</p><p>句子2：The Apple is a great company！——其中的Apple指的是苹果公司</p><p>而如果是传统的DNN（深度神经网络）模型，由于输入方式为逐元素输入，无法有效获取上下文信息，则若训练集中的apple一词大部分被标记为苹果食物，那么对测试集中的apple处理也将全部标记为苹果食物而非根据实际上下文推断。</p><h2 id="模型提出">模型提出</h2><h3 id="基本rnn结构">基本RNN结构</h3><p>为了解决普通DNN（深度神经网络）逐元素输入而无法有效获取上下文信息的问题。RNN最基本的改良点在于增加一个模块用于储存上下文信息，下图即是一个典型的RNN结构示意：</p><img src="https://caimotu.top/Picgo/image-20250417165208064.png" alt="image-20250417165208064" style="zoom:33%"><p>其中I（输入序列）到O（输出序列）的过程增加了一个保存上下文信息的权重矩阵W，也就是每次输出O不仅要考虑当前的输入数据I，还要考虑上一次输出的隐藏序列W（保存上下文）。RNN就是一个循环递归地处理上述输入输出的过程。</p><h3 id="rnn展开结构">RNN展开结构</h3><p>将上图的基本结构展开，就成为了下图展示的模型计算过程：</p><img src="https://caimotu.top/Picgo/ebe46967a3e80dab4c04635a2c6785f.jpg" alt="ebe46967a3e80dab4c04635a2c6785f" style="zoom:33%"><p>其中 <span class="math inline">\(x_i\)</span> 表示i时刻的模型输入，<span class="math inline">\(y_i\)</span>表示<span class="math inline">\(x_i\)</span>对应的输出结果，模型计算公式如下： <span class="math display">\[ \begin{split} y_i = g(Vh_i) \\ \\ h_i = f(Ux_i + Wh_{i-1}) \end{split} \]</span> U表示当前输入数据的权重因子，W表示决定上下文信息影响程度的参数矩阵，<span class="math inline">\(h_i\)</span>则表示当前隐藏层的输出隐变量。可以看出决定当前输出<span class="math inline">\(y_i\)</span>的隐变量<span class="math inline">\(h_i\)</span>不仅由当前输入<span class="math inline">\(x_i\)</span>决定，也与上一时刻的隐变量<span class="math inline">\(h_{i-1}\)</span>有关。（PS：整个模型计算过程里用的参数矩阵W是一定的）</p><h2 id="rnn模型结构变化">RNN模型结构变化</h2><p>上述展开结构会根据输入长度和输出长度的变化而产生不同的结构</p><h3 id="n-to-n结构">N to N结构</h3><p>这类结构的输入长度与输出长度相同，也即每一个输入值都会对应一个输出值。通常用于逐序列判断或分类任务（如序列标注，NER，视频帧分类等）。示例图与计算模型如2.2所述。</p><h3 id="n-to-1结构">N to 1结构</h3><p>这类结构只有一个输出值，表示输出结果包含了整个输入序列的语义信息和上下文信息。结构示意图：</p><img src="https://caimotu.top/Picgo/8606007dd425e9195f0c11d4719656f.jpg" alt="8606007dd425e9195f0c11d4719656f" style="zoom:50%"><p>计算模型： <span class="math display">\[ \begin{split} Y = y_N = g(Vh_N) \\ h_i = f(Ux_i+ Wh_{i-1}) \end{split} \]</span> 这类结构通常用于文字分类、文章分类以及图像分类任务。</p><h3 id="1-to-n结构">1 to N结构</h3><p>一个输入数据对应一系列输出，其意义是一个起始状态或种子数据会随时间变化生成一个序列的输出结果。</p><p>若输入数据只在首个时刻输入，则计算示意图如下所示：</p><img src="https://caimotu.top/Picgo/112ce7e4cbc3de28915ec314a82fdba.jpg" alt="112ce7e4cbc3de28915ec314a82fdba" style="zoom:50%"><p>而若输入数据在每个时刻都作为输入，则示意图如下：</p><img src="https://caimotu.top/Picgo/bd9767d63cc2fd88b9b265d80777250.jpg" alt="bd9767d63cc2fd88b9b265d80777250" style="zoom:50%"><p>该结构通常用于由图像自动生成文章、类别生成音乐、文章、代码等由种子数据生成序列的任务。</p><h3 id="n-to-m结构encoder-decoder模型seq2seq模型">N to M结构（encoder-decoder模型、seq2seq模型）</h3><p>最后一类是输入输出序列长度不相等的结构。通常采用一个N to 1结构和一个1 to M结构组合来实现，如下图：</p><img src="https://caimotu.top/Picgo/f529bf34ed1f0a34e98af6cd3b390b2.jpg" alt="f529bf34ed1f0a34e98af6cd3b390b2" style="zoom:50%"> <img src="https://caimotu.top/Picgo/6355d703227ac85b3ac67a61c52bd84.jpg" alt="6355d703227ac85b3ac67a61c52bd84" style="zoom:33%"><p>由上图可以看出，两个不同长度的RNN模型组合可以控制输出序列长度。两个模型之间通过一个上下文向量C来链接，其中C可作为第二个RNN模型的输入数据并对初始隐藏变量<span class="math inline">\(h_0^{&#39;}\)</span>​进行初始化（如第一个图），也可以直接被用来初始化第二个RNN模型的隐藏变量（如第二个图）。</p><p>常用的上下文向量C的求解方法有： <span class="math display">\[ \begin{split} c = h_N \\ c = g(h_N) \\ c = g(h_1 :: h_N) \end{split} \]</span> 第一种方法直接将encoder的输出作为上下文向量；第二种方法则需要先对encoder输出进行变换；第三种方法则将encoder的一个输出序列进行变换，而非单一选取最后一个输出。</p><p>通常将第一个RNN模型作为encoder（编码器），第二个RNN模型成为decoder（解码器）。通过这样N to M的RNN模型，我们可以处理各类序列处理任务，如语音识别，文本摘要，机器翻译，图像描述生成等。</p><h2 id="梯度消失与梯度爆炸">梯度消失与梯度爆炸</h2><h3 id="概念">概念</h3><p>由于RNN中的上下文参数矩阵是权重共享的，即当进行梯度更新时，对该矩阵求偏导数时需要加入时序影响，将导致存在基于时序数量的权重“连乘”。若某一阶段权重值过小，结合“连乘”将导致最终权重趋于“无穷小”（即等于0），此现象称为“梯度消失”。相反地，若权重值过大，经连乘后将导致权重值变得过大，称为“梯度爆炸”。</p><p>与普通NN的梯度消失及梯度爆炸不同，RNN的梯度爆炸（或消失）是根本原因是“连乘”，是在反向传播的某一阶段出现的，在此之前的反向传播不受影响。</p><h3 id="如何解决">如何解决</h3><p><strong>1. 梯度爆炸的解决</strong></p><p>1）梯度裁剪</p><p>​ 梯度裁剪即为梯度更新时的梯度设置上限，当超过阈值将强制裁剪，避免出现过高阈值。</p><p><strong>2. 梯度消失的解决</strong></p><p>1）使用Relu激活函数</p><p>​ 使用Relu激活函数解决梯度消失的原理是，Relu函数在自变量大于0是，因变量恒为1，由此避免梯度过小。</p><p>2）变更RNN结构</p><p>​ 改用变种版本的RNN结构，常见的包括LSTM模型及GRU模型。</p></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://ccloire.com">Loire</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://ccloire.com/2025/04/25/RNN%E7%AE%80%E4%BB%8B/">https://ccloire.com/2025/04/25/RNN%E7%AE%80%E4%BB%8B/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://ccloire.com" target="_blank">Loire's Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></div><div class="post-share"><div class="social-share" data-image="/img/butterfly-icon.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav id="pagination"><div class="pagination"></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/butterfly-icon.png" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="author-info-name">Loire</div><div class="author-info-description">记录CS学习路线以及各类经验分享</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">9</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">6</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/06/12/%E5%8D%97%E4%BA%AC4%E5%A4%A93%E5%A4%9C%E6%94%BB%E7%95%A5/" title="南京4天3夜攻略">南京4天3夜攻略</a><time datetime="2025-06-12T04:47:58.000Z" title="发表于 2025-06-12 12:47:58">2025-06-12</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/04/30/%E8%AE%A1%E7%BD%91%E5%AE%9E%E9%AA%8C-%E5%9F%BA%E6%9C%AC%E7%BD%91%E7%BB%9C%E6%8C%87%E4%BB%A4/" title="计网实验--基本网络指令">计网实验--基本网络指令</a><time datetime="2025-04-30T06:51:22.000Z" title="发表于 2025-04-30 14:51:22">2025-04-30</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/04/25/%E3%80%8AAttention%20is%20all%20your%20need%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" title="《Attention is all your need》论文笔记">《Attention is all your need》论文笔记</a><time datetime="2025-04-25T05:10:05.000Z" title="发表于 2025-04-25 13:10:05">2025-04-25</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/04/25/RNN%E7%AE%80%E4%BB%8B/" title="RNN简介">RNN简介</a><time datetime="2025-04-25T05:05:09.000Z" title="发表于 2025-04-25 13:05:09">2025-04-25</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/04/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C-%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%92%8C%E5%9B%A0%E7%89%B9%E7%BD%91/" title="计算机网络--第一章：计算机网络和因特网">计算机网络--第一章：计算机网络和因特网</a><time datetime="2025-04-08T07:11:17.000Z" title="发表于 2025-04-08 15:11:17">2025-04-08</time></div></div></div></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size:1.1em;color:#999">深度学习</a> <a href="/tags/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0/" style="font-size:1.1em;color:#999">多模态大模型论文学习</a> <a href="/tags/%E7%94%9F%E6%B4%BB/" style="font-size:1.1em;color:#999">生活</a> <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" style="font-size:1.1em;color:#999">计算机网络</a> <a href="/tags/%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/" style="font-size:1.1em;color:#999">技术分享</a> <a href="/tags/%E5%9F%BA%E7%A1%80%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/" style="font-size:1.1em;color:#999">基础工具使用指南</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i> <span>归档</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/06/"><span class="card-archive-list-date">六月 2025 </span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/04/"><span class="card-archive-list-date">四月 2025 </span><span class="card-archive-list-count">4</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/03/"><span class="card-archive-list-date">三月 2025 </span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/02/"><span class="card-archive-list-date">二月 2025 </span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/01/"><span class="card-archive-list-date">一月 2025 </span><span class="card-archive-list-count">1</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站信息</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">9</div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">本站总浏览量 :</div><div class="item-count" id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastpushdate="2025-06-12T13:31:25.222Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By Loire</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.5</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(()=>{const e=()=>{(()=>{const e=document.querySelectorAll("pre > code.mermaid");0!==e.length&&e.forEach(e=>{const t=document.createElement("pre");t.className="mermaid-src",t.hidden=!0,t.textContent=e.textContent;const n=document.createElement("div");n.className="mermaid-wrap",n.appendChild(t),e.parentNode.replaceWith(n)})})();const e=document.querySelectorAll("#article-container .mermaid-wrap");if(0===e.length)return;const t=()=>(e=>{window.loadMermaid=!0;const t="dark"===document.documentElement.getAttribute("data-theme")?"dark":"default";e.forEach((e,n)=>{const d=e.firstElementChild,a="mermaid-"+n,r=`%%{init:{ 'theme':'${t}'}}%%\n`+d.textContent,m=mermaid.render(a,r),o=e=>{d.insertAdjacentHTML("afterend",e)};"string"==typeof m?o(m):m.then(({svg:e})=>o(e))})})(e);btf.addGlobalFn("themeChange",t,"mermaid"),window.loadMermaid?t():btf.getScript("https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js").then(t)};btf.addGlobalFn("encrypt",e,"mermaid"),window.pjax?e():document.addEventListener("DOMContentLoaded",e)})()</script><script>(()=>{const t=(e,a)=>{"object"==typeof e&&null!==e&&Object.keys(e).forEach(r=>{const n=e[r];"object"==typeof n&&null!==n&&(n[a]?e[r]=n[a]:t(n,a))})},e=e=>{window.loadChartJS=!0,Array.from(e).forEach((e,a)=>{const r=e.firstElementChild,n=e.getAttribute("data-chartjs-id")||"chartjs-"+a,d=e.getAttribute("data-width"),o=document.getElementById(n);o&&o.parentNode.remove();const c=r.textContent,l=document.createElement("canvas");l.id=n;const s=document.createElement("div");s.className="chartjs-wrap",d&&(s.style.width=d),s.appendChild(l),r.insertAdjacentElement("afterend",s);const h=document.getElementById(n).getContext("2d"),i=JSON.parse(c),m="dark"===document.documentElement.getAttribute("data-theme")?"dark-mode":"light-mode";(t=>{"dark-mode"===t?(Chart.defaults.color="rgba(255, 255, 255, 0.8)",Chart.defaults.borderColor="rgba(255, 255, 255, 0.2)",Chart.defaults.scale.ticks.backdropColor="transparent"):(Chart.defaults.color="rgba(0, 0, 0, 0.8)",Chart.defaults.borderColor="rgba(0, 0, 0, 0.1)",Chart.defaults.scale.ticks.backdropColor="transparent")})(m),t(i,m),new Chart(h,i)})},a=()=>{const t=document.querySelectorAll("#article-container .chartjs-container");0!==t.length&&(window.loadChartJS?e(t):btf.getScript("https://cdn.jsdelivr.net/npm/chart.js/dist/chart.umd.min.js").then(()=>e(t)))};btf.addGlobalFn("themeChange",a,"chartjs"),btf.addGlobalFn("encrypt",a,"chartjs"),window.pjax?a():document.addEventListener("DOMContentLoaded",a)})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>